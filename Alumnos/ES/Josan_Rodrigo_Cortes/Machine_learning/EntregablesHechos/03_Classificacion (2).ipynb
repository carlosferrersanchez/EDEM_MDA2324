{"cells":[{"cell_type":"markdown","metadata":{"id":"mYJdsFxinuN5"},"source":["# ENTREGABLE 4"]},{"cell_type":"markdown","metadata":{"id":"IIGQAc67cj6O"},"source":["# INSTRUCCIONES"]},{"cell_type":"markdown","metadata":{"id":"t3VhhDXrcfBJ"},"source":["Utilizar el archivo CSV (`dataset_banco_clean.csv`) con 45189 filas y 17 columnas y aplicar las técnicas de normalización del entregable 3."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"LDnXEh9vn2GX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: scikit-learn in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.4.1.post1)\n","Requirement already satisfied: imblearn in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.0)\n","Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.24.4)\n","Requirement already satisfied: scipy>=1.6.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.12.0)\n","Requirement already satisfied: joblib>=1.2.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from scikit-learn) (3.4.0)\n","Requirement already satisfied: imbalanced-learn in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imblearn) (0.12.2)\n","Requirement already satisfied: xgboost in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.0.3)\n","Requirement already satisfied: numpy in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.24.4)\n","Requirement already satisfied: scipy in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from xgboost) (1.12.0)\n","Requirement already satisfied: lightgbm in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.3.0)\n","Requirement already satisfied: numpy in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.24.4)\n","Requirement already satisfied: scipy in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from lightgbm) (1.12.0)\n","Requirement already satisfied: catboost in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.2.3)\n","Requirement already satisfied: graphviz in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (0.20.3)\n","Requirement already satisfied: matplotlib in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (3.8.2)\n","Requirement already satisfied: numpy>=1.16.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.24.4)\n","Requirement already satisfied: pandas>=0.24 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.5.3)\n","Requirement already satisfied: scipy in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.12.0)\n","Requirement already satisfied: plotly in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (5.19.0)\n","Requirement already satisfied: six in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from catboost) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (23.2)\n","Requirement already satisfied: pillow>=8 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (10.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->catboost) (3.1.1)\n","Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\josan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from plotly->catboost) (8.2.3)\n"]}],"source":["# Módulos necesarios\n","!pip install scikit-learn imblearn\n","!pip install xgboost\n","!pip install lightgbm\n","!pip install catboost\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib as plt\n","import matplotlib.pyplot as plt\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from scipy.stats import expon, reciprocal\n","from imblearn.over_sampling import SMOTE\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import IterativeImputer\n","\n","# Clasificadores\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier, StackingClassifier, HistGradientBoostingClassifier\n","# from sklearn.svm import SVC\n","# from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.linear_model import RidgeClassifier\n","from catboost import CatBoostClassifier\n","from lightgbm import LGBMClassifier\n","from xgboost import XGBClassifier\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.datasets import load_iris\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2C6TxrrjoLca"},"outputs":[],"source":["\n","iris=load_iris()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>species</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n","0                5.1               3.5                1.4               0.2   \n","1                4.9               3.0                1.4               0.2   \n","2                4.7               3.2                1.3               0.2   \n","3                4.6               3.1                1.5               0.2   \n","4                5.0               3.6                1.4               0.2   \n","\n","  species  \n","0  setosa  \n","1  setosa  \n","2  setosa  \n","3  setosa  \n","4  setosa  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n","\n","# Añadir la columna de etiquetas al DataFrame\n","data['species'] = iris.target\n","data['species'] = data['species'].apply(lambda x: iris.target_names[x])\n","data.head(5)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["sepal length (cm)    0\n","sepal width (cm)     0\n","petal length (cm)    0\n","petal width (cm)     0\n","species              0\n","dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["data.isna().sum()"]},{"cell_type":"markdown","metadata":{"id":"suOncPeIo2Ln"},"source":["# Objetivo\n","\n","Generar un model de clasificación capaz de predecir la clase de flor en función de las carácterísticas del dataset\n","\n","* Aplicar las técnicas oportunas de procesamiento de datos\n","\n","* Generar split de los datos\n","\n","* Valorar diferentes modelos de clasificación\n","\n","* Comparación entre modelos\n","\n","* Ensemble\n","\n","* Métricas\n","\n","* Conclusiones finales"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Asignaciones de Label Encoder para cada columna:\n","species: {'setosa': 0, 'versicolor': 1, 'virginica': 2}\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","label_mappings={}\n","\n","le = LabelEncoder()\n","\n","data['species'] = le.fit_transform(data['species'])\n","# Almacenar las clases y sus etiquetas correspondientes\n","label_mappings['species'] = dict(zip(le.classes_, le.transform(le.classes_)))\n","\n","print(\"\\nAsignaciones de Label Encoder para cada columna:\")\n","for column, mappings in label_mappings.items():\n","    print(f\"{column}: {mappings}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"oGEq8EGTpp7g"},"outputs":[],"source":["# Definimos el set de características y el set de la variable a predecir Y\n","X = data.drop(columns='species')\n","Y = data['species']"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Entrenamiento: (127, 4) (127,)\n","Validación: (23, 4) (23,)\n","Prueba: (23, 4) (23,)\n"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15)\n","X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.15)\n","print(\"Entrenamiento:\", X_train.shape, y_train.shape)\n","print(\"Validación:\", X_val.shape, y_val.shape)\n","print(\"Prueba:\", X_test.shape, y_test.shape)"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["modelos_mapeados = {\n","    \"Regresión Logística\": LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=200),\n","    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n","    \"Árboles de Decisión\": DecisionTreeClassifier(),\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"Gradient Boosting\": GradientBoostingClassifier(),\n","    \"Máquinas de Vectores de Soporte (SVM)\": SVC(probability=True),\n","    \"AdaBoost\": AdaBoostClassifier(),\n","    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),\n","    \"Clasificador de Vecinos Ponderados (WKNN)\": KNeighborsClassifier(),\n","    \"Extra Trees\": ExtraTreesClassifier(),\n","    \"Bagging Classifier\": BaggingClassifier(),\n","    \"Histogram-Based Gradient Boosting\": HistGradientBoostingClassifier(),\n","    \"Gaussian Process Classifier\": GaussianProcessClassifier(),\n","    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n","    \"Gaussian Naive Bayes\": GaussianNB(),\n","    \"Calibrated Classifier\": CalibratedClassifierCV(),\n","    \"Ridge Classifier\": RidgeClassifier(),\n","}"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Precisión del modelo Regresión Logística: 0.9565217391304348\n","Puntaje F1 del modelo Regresión Logística: 0.9563871315116436\n","Matriz de confusión para el modelo Regresión Logística:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo K-Nearest Neighbors (KNN): 0.9130434782608695\n","Puntaje F1 del modelo K-Nearest Neighbors (KNN): 0.9130434782608695\n","Matriz de confusión para el modelo K-Nearest Neighbors (KNN):\n","[[5 0 0]\n"," [0 8 1]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Árboles de Decisión: 0.8695652173913043\n","Puntaje F1 del modelo Árboles de Decisión: 0.8691613945349306\n","Matriz de confusión para el modelo Árboles de Decisión:\n","[[5 0 0]\n"," [0 8 1]\n"," [0 2 7]]\n","\n","\n","Precisión del modelo Random Forest: 0.9130434782608695\n","Puntaje F1 del modelo Random Forest: 0.9130434782608695\n","Matriz de confusión para el modelo Random Forest:\n","[[5 0 0]\n"," [0 8 1]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Gradient Boosting: 0.9130434782608695\n","Puntaje F1 del modelo Gradient Boosting: 0.9119565217391304\n","Matriz de confusión para el modelo Gradient Boosting:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 2 7]]\n","\n","\n","Precisión del modelo Máquinas de Vectores de Soporte (SVM): 0.9565217391304348\n","Puntaje F1 del modelo Máquinas de Vectores de Soporte (SVM): 0.9563871315116436\n","Matriz de confusión para el modelo Máquinas de Vectores de Soporte (SVM):\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo AdaBoost: 0.9565217391304348\n","Puntaje F1 del modelo AdaBoost: 0.9563871315116436\n","Matriz de confusión para el modelo AdaBoost:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo XGBoost: 0.9130434782608695\n","Puntaje F1 del modelo XGBoost: 0.9119565217391304\n","Matriz de confusión para el modelo XGBoost:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 2 7]]\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\josan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Precisión del modelo Clasificador de Vecinos Ponderados (WKNN): 0.9130434782608695\n","Puntaje F1 del modelo Clasificador de Vecinos Ponderados (WKNN): 0.9130434782608695\n","Matriz de confusión para el modelo Clasificador de Vecinos Ponderados (WKNN):\n","[[5 0 0]\n"," [0 8 1]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Extra Trees: 0.9130434782608695\n","Puntaje F1 del modelo Extra Trees: 0.9130434782608695\n","Matriz de confusión para el modelo Extra Trees:\n","[[5 0 0]\n"," [0 8 1]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Bagging Classifier: 0.8695652173913043\n","Puntaje F1 del modelo Bagging Classifier: 0.8691613945349306\n","Matriz de confusión para el modelo Bagging Classifier:\n","[[5 0 0]\n"," [0 8 1]\n"," [0 2 7]]\n","\n","\n","Precisión del modelo Histogram-Based Gradient Boosting: 0.8695652173913043\n","Puntaje F1 del modelo Histogram-Based Gradient Boosting: 0.8691613945349306\n","Matriz de confusión para el modelo Histogram-Based Gradient Boosting:\n","[[5 0 0]\n"," [0 7 2]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Gaussian Process Classifier: 0.9130434782608695\n","Puntaje F1 del modelo Gaussian Process Classifier: 0.9119565217391304\n","Matriz de confusión para el modelo Gaussian Process Classifier:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 2 7]]\n","\n","\n","Precisión del modelo Decision Tree Classifier: 0.8260869565217391\n","Puntaje F1 del modelo Decision Tree Classifier: 0.8260869565217391\n","Matriz de confusión para el modelo Decision Tree Classifier:\n","[[5 0 0]\n"," [0 7 2]\n"," [0 2 7]]\n","\n","\n","Precisión del modelo Gaussian Naive Bayes: 0.9565217391304348\n","Puntaje F1 del modelo Gaussian Naive Bayes: 0.9563871315116436\n","Matriz de confusión para el modelo Gaussian Naive Bayes:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Calibrated Classifier: 0.8695652173913043\n","Puntaje F1 del modelo Calibrated Classifier: 0.8691613945349306\n","Matriz de confusión para el modelo Calibrated Classifier:\n","[[5 0 0]\n"," [0 7 2]\n"," [0 1 8]]\n","\n","\n","Precisión del modelo Ridge Classifier: 0.8260869565217391\n","Puntaje F1 del modelo Ridge Classifier: 0.8239130434782609\n","Matriz de confusión para el modelo Ridge Classifier:\n","[[5 0 0]\n"," [0 6 3]\n"," [0 1 8]]\n","\n","\n"]}],"source":["from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n","\n","# Crear una lista para almacenar la precisión de cada modelo\n","precisiones = []\n","\n","# Iterar sobre los modelos de clasificación\n","for modelo_nombre in modelos_mapeados.keys():\n","    # Crear un nuevo modelo para cada iteración\n","    modelo_clase = modelos_mapeados[modelo_nombre]  # Obtener la clase del modelo\n","    modelo = modelo_clase  # Crear una instancia del modelo\n","    \n","    # Entrenar el clasificador con los datos de entrenamiento\n","    modelo.fit(X_train, y_train)\n","    \n","    # Hacer predicciones en los datos de validación\n","    y_pred_val = modelo.predict(X_val)\n","    \n","    # Calcular la precisión del modelo en los datos de validación\n","    precision = accuracy_score(y_val, y_pred_val)\n","    \n","    # Calcular el puntaje F1 del modelo en los datos de validación\n","    puntaje_f1 = f1_score(y_val, y_pred_val, average='weighted')  # 'macro' es útil cuando tienes clases desbalanceadas\n","    \n","    # Almacenar la precisión y el puntaje F1 del modelo\n","    precisiones.append((modelo_nombre, precision, puntaje_f1))\n","\n","    print(f\"Precisión del modelo {modelo_nombre}:\", precision)\n","    print(f\"Puntaje F1 del modelo {modelo_nombre}:\", puntaje_f1)\n","    \n","    # Calcular y mostrar la matriz de confusión\n","    matriz_confusion = confusion_matrix(y_val, y_pred_val)\n","    print(f\"Matriz de confusión para el modelo {modelo_nombre}:\")\n","    print(matriz_confusion)\n","    print(\"\\n\")"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\josan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]}],"source":["from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n","\n","# Lista para almacenar los resultados de cada modelo\n","resultados_modelos = []\n","\n","# Iterar sobre los modelos de clasificación\n","for modelo_nombre, modelo_clase in modelos_mapeados.items():\n","    try:\n","        # Crear e instanciar el modelo\n","        modelo = modelo_clase\n","\n","        # Entrenar el clasificador con los datos de entrenamiento\n","        modelo.fit(X_train, y_train)\n","\n","        # Hacer predicciones en los datos de validación\n","        y_pred_val = modelo.predict(X_val)\n","\n","        # Calcular la precisión y el puntaje F1\n","        precision = accuracy_score(y_val, y_pred_val)\n","        puntaje_f1 = f1_score(y_val, y_pred_val, average='weighted')\n","\n","        # Guardar resultados en la lista\n","        resultados_modelos.append({\n","            'modelo': modelo_nombre,\n","            'precisión': precision,\n","            'puntaje_f1': puntaje_f1,\n","            'matriz_confusión': confusion_matrix(y_val, y_pred_val)\n","        })\n","\n","    except Exception as e:\n","        print(f\"Error al entrenar o evaluar el modelo {modelo_nombre}: {e}\")\n"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'modelo': 'Regresión Logística', 'precisión': 0.9565217391304348, 'puntaje_f1': 0.9563871315116436, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'K-Nearest Neighbors (KNN)', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9130434782608695, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 8, 1],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Árboles de Decisión', 'precisión': 0.8695652173913043, 'puntaje_f1': 0.8691613945349306, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 8, 1],\n","       [0, 2, 7]], dtype=int64)}, {'modelo': 'Random Forest', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9130434782608695, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 8, 1],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Gradient Boosting', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9119565217391304, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 2, 7]], dtype=int64)}, {'modelo': 'Máquinas de Vectores de Soporte (SVM)', 'precisión': 0.9565217391304348, 'puntaje_f1': 0.9563871315116436, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'AdaBoost', 'precisión': 0.9565217391304348, 'puntaje_f1': 0.9563871315116436, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'XGBoost', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9119565217391304, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 2, 7]], dtype=int64)}, {'modelo': 'Clasificador de Vecinos Ponderados (WKNN)', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9130434782608695, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 8, 1],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Extra Trees', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9130434782608695, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 8, 1],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Bagging Classifier', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9119565217391304, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 2, 7]], dtype=int64)}, {'modelo': 'Histogram-Based Gradient Boosting', 'precisión': 0.8695652173913043, 'puntaje_f1': 0.8691613945349306, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 7, 2],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Gaussian Process Classifier', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9119565217391304, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 2, 7]], dtype=int64)}, {'modelo': 'Decision Tree Classifier', 'precisión': 0.9130434782608695, 'puntaje_f1': 0.9119565217391304, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 2, 7]], dtype=int64)}, {'modelo': 'Gaussian Naive Bayes', 'precisión': 0.9565217391304348, 'puntaje_f1': 0.9563871315116436, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 9, 0],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Calibrated Classifier', 'precisión': 0.8695652173913043, 'puntaje_f1': 0.8691613945349306, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 7, 2],\n","       [0, 1, 8]], dtype=int64)}, {'modelo': 'Ridge Classifier', 'precisión': 0.8260869565217391, 'puntaje_f1': 0.8239130434782609, 'matriz_confusión': array([[5, 0, 0],\n","       [0, 6, 3],\n","       [0, 1, 8]], dtype=int64)}]\n"]}],"source":["print(resultados_modelos)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Modelo: Regresión Logística\n","Precisión: 0.9565217391304348\n","Puntaje F1: 0.9563871315116436\n","Matriz de confusión:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","Modelo: Máquinas de Vectores de Soporte (SVM)\n","Precisión: 0.9565217391304348\n","Puntaje F1: 0.9563871315116436\n","Matriz de confusión:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","Modelo: AdaBoost\n","Precisión: 0.9565217391304348\n","Puntaje F1: 0.9563871315116436\n","Matriz de confusión:\n","[[5 0 0]\n"," [0 9 0]\n"," [0 1 8]]\n","\n","['Regresión Logística', 'Máquinas de Vectores de Soporte (SVM)', 'AdaBoost']\n"]}],"source":["# Ordenar los modelos por puntaje F1 de mayor a menor\n","resultados_modelos.sort(key=lambda x: x['puntaje_f1'], reverse=True)\n","\n","# Seleccionar los tres modelos con mejores puntajes F1\n","mejores_tres_modelos = resultados_modelos[:3]\n","modelos_elegidos=[]\n","# Imprimir los resultados de los tres mejores modelos\n","for modelo in mejores_tres_modelos:\n","    print(f\"Modelo: {modelo['modelo']}\")\n","    print(f\"Precisión: {modelo['precisión']}\")\n","    print(f\"Puntaje F1: {modelo['puntaje_f1']}\")\n","    print(f\"Matriz de confusión:\\n{modelo['matriz_confusión']}\\n\")\n","    modelos_elegidos.append(modelo['modelo'])\n","\n","print(modelos_elegidos)\n"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[('Regresión Logística', LogisticRegression(max_iter=200, multi_class='multinomial')), ('Máquinas de Vectores de Soporte (SVM)', SVC(probability=True)), ('AdaBoost', AdaBoostClassifier())]\n"]}],"source":["mejores_modelos = [(nombre, modelos_mapeados[nombre]) for nombre in modelos_elegidos]\n","print(mejores_modelos)\n"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\josan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Ensemble entrenado con éxito.\n","El ensemble tiene una precisión de 0.96 en el conjunto de prueba.\n"]}],"source":["from sklearn.ensemble import VotingClassifier\n","\n","# Crear el ensemble por votación\n","ensemble = VotingClassifier(estimators=mejores_modelos, voting='soft')\n","ensemble.fit(X_train, y_train)\n","print(\"Ensemble entrenado con éxito.\")\n","\n","# Evaluar el ensemble en el conjunto de prueba\n","ensemble_score = ensemble.score(X_val, y_val)\n","print(f\"El ensemble tiene una precisión de {ensemble_score:.2f} en el conjunto de prueba.\")\n"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Precisión en el conjunto de entrenamiento: 0.984251968503937\n","Precisión en el conjunto de prueba: 0.9565217391304348\n"]}],"source":["from sklearn.ensemble import VotingClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Crear el VotingClassifier con modelos específicos\n","ensemble = VotingClassifier(estimators=[\n","    ('lr', LogisticRegression(max_iter=200, multi_class='multinomial')),\n","    ('svm', SVC(probability=True)),  # Asegúrate de habilitar las probabilidades si usas votación 'soft'\n","    ('dt', DecisionTreeClassifier())\n","], voting='hard')  # Puedes cambiar a 'hard' si no necesitas estimar probabilidades\n","\n","# Suponiendo que tienes X_train y y_train\n","ensemble.fit(X_train, y_train)\n","\n","# Evaluar el ensemble\n","print(\"Precisión en el conjunto de entrenamiento:\", ensemble.score(X_train, y_train))\n","print(\"Precisión en el conjunto de prueba:\", ensemble.score(X_test, y_test))\n"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El ensemble tiene una precisión de 0.96 en el conjunto de test.\n"]}],"source":["\n","\n","# Evaluar el ensemble en el conjunto de prueba\n","ensemble_score = ensemble.score(X_test, y_test)\n","print(f\"El ensemble tiene una precisión de {ensemble_score:.2f} en el conjunto de test.\")\n"]},{"cell_type":"markdown","metadata":{"id":"j2PGzN9SpfcP"},"source":["# Conclusiones"]},{"cell_type":"markdown","metadata":{},"source":["Aumentar la complejidad del algoritmo utilizando un ensemble, no hace que mejoren nuestros resultados."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
