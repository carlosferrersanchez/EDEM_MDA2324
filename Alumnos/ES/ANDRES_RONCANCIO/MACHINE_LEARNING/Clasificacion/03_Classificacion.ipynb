{"cells":[{"cell_type":"markdown","metadata":{"id":"mYJdsFxinuN5"},"source":["# ENTREGABLE 4"]},{"cell_type":"markdown","metadata":{"id":"IIGQAc67cj6O"},"source":["# INSTRUCCIONES"]},{"cell_type":"markdown","metadata":{"id":"t3VhhDXrcfBJ"},"source":["Utilizar el archivo CSV (`dataset_banco_clean.csv`) con 45189 filas y 17 columnas y aplicar las técnicas de normalización del entregable 3."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1604,"status":"ok","timestamp":1714310960179,"user":{"displayName":"Andrés Roncancio","userId":"06846180829223349543"},"user_tz":-120},"id":"LDnXEh9vn2GX"},"outputs":[],"source":["# imports\n","from sklearn.datasets import load_iris\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":595,"status":"ok","timestamp":1714311024857,"user":{"displayName":"Andrés Roncancio","userId":"06846180829223349543"},"user_tz":-120},"id":"2C6TxrrjoLca","outputId":"2b183530-d6b7-403b-be3f-be1f04ae0fc6"},"outputs":[],"source":["ruta = \"./dataset_banco_clean.csv\"\n","data_cleaned = pd.read_csv(ruta)"]},{"cell_type":"markdown","metadata":{"id":"suOncPeIo2Ln"},"source":["# Objetivo\n","\n","Generar un model de clasificación capaz de predecir la clase de flor en función de las carácterísticas del dataset\n","\n","* Aplicar las técnicas oportunas de procesamiento de datos\n","\n","* Generar split de los datos\n","\n","* Valorar diferentes modelos de clasificación\n","\n","* Comparación entre modelos\n","\n","* Ensemble\n","\n","* Métricas\n","\n","* Conclusiones finales"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1714311078362,"user":{"displayName":"Andrés Roncancio","userId":"06846180829223349543"},"user_tz":-120},"id":"oGEq8EGTpp7g","outputId":"cde72c74-7915-469a-a7ff-4c7f1ddd0a37"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>job</th>\n","      <th>marital</th>\n","      <th>education</th>\n","      <th>default</th>\n","      <th>balance</th>\n","      <th>housing</th>\n","      <th>loan</th>\n","      <th>contact</th>\n","      <th>day</th>\n","      <th>month</th>\n","      <th>duration</th>\n","      <th>campaign</th>\n","      <th>pdays</th>\n","      <th>previous</th>\n","      <th>poutcome</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58</td>\n","      <td>management</td>\n","      <td>married</td>\n","      <td>tertiary</td>\n","      <td>no</td>\n","      <td>2143.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>261.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44</td>\n","      <td>technician</td>\n","      <td>single</td>\n","      <td>secondary</td>\n","      <td>no</td>\n","      <td>29.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>151.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33</td>\n","      <td>entrepreneur</td>\n","      <td>married</td>\n","      <td>secondary</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>76.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>47</td>\n","      <td>blue-collar</td>\n","      <td>married</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","      <td>1506.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>92.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33</td>\n","      <td>unknown</td>\n","      <td>single</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","      <td>1.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>198.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age           job  marital  education default  balance housing loan  \\\n","0   58    management  married   tertiary      no   2143.0     yes   no   \n","1   44    technician   single  secondary      no     29.0     yes   no   \n","2   33  entrepreneur  married  secondary      no      2.0     yes  yes   \n","3   47   blue-collar  married    unknown      no   1506.0     yes   no   \n","4   33       unknown   single    unknown      no      1.0      no   no   \n","\n","   contact  day month  duration  campaign  pdays  previous poutcome   y  \n","0  unknown    5   may     261.0         1   -1.0         0  unknown  no  \n","1  unknown    5   may     151.0         1   -1.0         0  unknown  no  \n","2  unknown    5   may      76.0         1   -1.0         0  unknown  no  \n","3  unknown    5   may      92.0         1   -1.0         0  unknown  no  \n","4  unknown    5   may     198.0         1   -1.0         0  unknown  no  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data_cleaned.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Normalizacion:"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":269},"executionInfo":{"elapsed":269,"status":"error","timestamp":1714311545798,"user":{"displayName":"Andrés Roncancio","userId":"06846180829223349543"},"user_tz":-120},"id":"6eBnJpgV7Vbe","outputId":"0b8ab828-5da1-4202-a966-a846c32c62b9"},"outputs":[{"data":{"text/plain":["Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n","       'loan', 'contact', 'day', 'month', 'duration', 'campaign', 'pdays',\n","       'previous', 'poutcome', 'y'],\n","      dtype='object')"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# First, let's ensure that numerical columns are treated as numeric data_cleaned types.\n","\n","# Identify columns that should be numeric but are currently object type\n","numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n","\n","# Attempt to convert these columns to numeric, coercing errors which will turn non-convertible values to NaN\n","data_cleaned[numeric_cols] = data_cleaned[numeric_cols].apply(pd.to_numeric, errors='coerce')\n","\n","# Check the data_cleaned types again to confirm changes and identify any columns with unexpected NaNs introduced by coercing\n","data_cleaned.dtypes, data_cleaned[numeric_cols].isnull().sum()\n","\n","data_cleaned.columns\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","Name: y_encoded, dtype: int64\n"]}],"source":["from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n","\n","# Apply OneHotEncoder to the categorical columns\n","# Initialize OneHotEncoder without the 'sparse' argument\n","encoder_corrected = OneHotEncoder()\n","\n","# List of categorical columns for OneHotEncoding\n","categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n","\n","# Encode the target variable 'y' using LabelEncoder\n","label_encoder = LabelEncoder()\n","data_cleaned['y_encoded'] = label_encoder.fit_transform(data_cleaned['y'])\n","\n","# Apply OneHotEncoder to the categorical columns again\n","data_encoded_corrected = pd.DataFrame(encoder_corrected.fit_transform(data_cleaned[categorical_columns]).toarray(),\n","                                      columns=encoder_corrected.get_feature_names_out(categorical_columns))\n","\n","# Reindex to align with the original data indices after dropna\n","data_encoded_corrected.index = data_cleaned.index\n","\n","# Drop the original categorical columns and concatenate the encoded columns, including 'y_encoded'\n","data_final_corrected = pd.concat([data_cleaned.drop(categorical_columns + ['y'], axis=1), data_encoded_corrected], axis=1)\n","\n","# Verify if 'y_encoded' is present and correctly formed\n","print(data_final_corrected['y_encoded'].head())\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>balance</th>\n","      <th>day</th>\n","      <th>duration</th>\n","      <th>campaign</th>\n","      <th>pdays</th>\n","      <th>previous</th>\n","      <th>y_encoded</th>\n","      <th>job_administrative</th>\n","      <th>job_blue-collar</th>\n","      <th>...</th>\n","      <th>month_jun</th>\n","      <th>month_mar</th>\n","      <th>month_may</th>\n","      <th>month_nov</th>\n","      <th>month_oct</th>\n","      <th>month_sep</th>\n","      <th>poutcome_failure</th>\n","      <th>poutcome_other</th>\n","      <th>poutcome_success</th>\n","      <th>poutcome_unknown</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58</td>\n","      <td>2143.0</td>\n","      <td>5</td>\n","      <td>261.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44</td>\n","      <td>29.0</td>\n","      <td>5</td>\n","      <td>151.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33</td>\n","      <td>2.0</td>\n","      <td>5</td>\n","      <td>76.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>47</td>\n","      <td>1506.0</td>\n","      <td>5</td>\n","      <td>92.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33</td>\n","      <td>1.0</td>\n","      <td>5</td>\n","      <td>198.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 52 columns</p>\n","</div>"],"text/plain":["   age  balance  day  duration  campaign  pdays  previous  y_encoded  \\\n","0   58   2143.0    5     261.0         1   -1.0         0          0   \n","1   44     29.0    5     151.0         1   -1.0         0          0   \n","2   33      2.0    5      76.0         1   -1.0         0          0   \n","3   47   1506.0    5      92.0         1   -1.0         0          0   \n","4   33      1.0    5     198.0         1   -1.0         0          0   \n","\n","   job_administrative  job_blue-collar  ...  month_jun  month_mar  month_may  \\\n","0                 0.0              0.0  ...        0.0        0.0        1.0   \n","1                 0.0              0.0  ...        0.0        0.0        1.0   \n","2                 0.0              0.0  ...        0.0        0.0        1.0   \n","3                 0.0              1.0  ...        0.0        0.0        1.0   \n","4                 0.0              0.0  ...        0.0        0.0        1.0   \n","\n","   month_nov  month_oct  month_sep  poutcome_failure  poutcome_other  \\\n","0        0.0        0.0        0.0               0.0             0.0   \n","1        0.0        0.0        0.0               0.0             0.0   \n","2        0.0        0.0        0.0               0.0             0.0   \n","3        0.0        0.0        0.0               0.0             0.0   \n","4        0.0        0.0        0.0               0.0             0.0   \n","\n","   poutcome_success  poutcome_unknown  \n","0               0.0               1.0  \n","1               0.0               1.0  \n","2               0.0               1.0  \n","3               0.0               1.0  \n","4               0.0               1.0  \n","\n","[5 rows x 52 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["data_final_corrected.head()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>balance</th>\n","      <th>day</th>\n","      <th>duration</th>\n","      <th>campaign</th>\n","      <th>pdays</th>\n","      <th>previous</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>45189.000000</td>\n","      <td>45189.000000</td>\n","      <td>45189.000000</td>\n","      <td>45189.000000</td>\n","      <td>45189.000000</td>\n","      <td>45189.000000</td>\n","      <td>45189.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>0.297876</td>\n","      <td>0.017539</td>\n","      <td>0.493573</td>\n","      <td>0.052291</td>\n","      <td>0.028440</td>\n","      <td>0.047224</td>\n","      <td>0.009899</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.137903</td>\n","      <td>0.007328</td>\n","      <td>0.277418</td>\n","      <td>0.052339</td>\n","      <td>0.049945</td>\n","      <td>0.114802</td>\n","      <td>0.032896</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>0.194805</td>\n","      <td>0.015108</td>\n","      <td>0.233333</td>\n","      <td>0.020744</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>0.272727</td>\n","      <td>0.015810</td>\n","      <td>0.500000</td>\n","      <td>0.036404</td>\n","      <td>0.016129</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>0.389610</td>\n","      <td>0.017640</td>\n","      <td>0.666667</td>\n","      <td>0.064674</td>\n","      <td>0.032258</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                age       balance           day      duration      campaign  \\\n","count  45189.000000  45189.000000  45189.000000  45189.000000  45189.000000   \n","mean       0.297876      0.017539      0.493573      0.052291      0.028440   \n","std        0.137903      0.007328      0.277418      0.052339      0.049945   \n","min        0.000000      0.000000      0.000000      0.000000      0.000000   \n","25%        0.194805      0.015108      0.233333      0.020744      0.000000   \n","50%        0.272727      0.015810      0.500000      0.036404      0.016129   \n","75%        0.389610      0.017640      0.666667      0.064674      0.032258   \n","max        1.000000      1.000000      1.000000      1.000000      1.000000   \n","\n","              pdays      previous  \n","count  45189.000000  45189.000000  \n","mean       0.047224      0.009899  \n","std        0.114802      0.032896  \n","min        0.000000      0.000000  \n","25%        0.000000      0.000000  \n","50%        0.000000      0.000000  \n","75%        0.000000      0.000000  \n","max        1.000000      1.000000  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","# Initialize the MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","# List of numeric columns to normalize\n","numeric_cols = ['age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous']\n","\n","# Apply MinMaxScaler to the numeric columns\n","data_final_corrected[numeric_cols] = scaler.fit_transform(data_final_corrected[numeric_cols])\n","\n","# Show summary statistics of the normalized columns to verify the transformation\n","data_final_corrected[numeric_cols].describe()"]},{"cell_type":"markdown","metadata":{},"source":["## Split de datos:"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["((36151, 51), (4519, 51), (4519, 51))"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","\n","# Define the features and target variable\n","X = data_final_corrected.drop('y_encoded', axis=1)\n","y = data_final_corrected['y_encoded']\n","\n","# Split the data into training and temporary set (80% - 20%)\n","X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Split the temporary set into validation and test set (50% - 50%)\n","X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n","\n","# Print the shapes of the splits to confirm their sizes\n","X_train.shape, X_val.shape, X_test.shape\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["array([0, 1])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["data_final_corrected['y_encoded'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["# Modelos"]},{"cell_type":"markdown","metadata":{},"source":["## Regresion Logistica:"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9006417348971011               precision    recall  f1-score   support\n","\n","           0       0.92      0.98      0.95      3987\n","           1       0.66      0.32      0.43       532\n","\n","    accuracy                           0.90      4519\n","   macro avg       0.79      0.65      0.69      4519\n","weighted avg       0.89      0.90      0.89      4519\n","\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Initialize the Logistic Regression model\n","log_reg = LogisticRegression(random_state=42, max_iter=1000)\n","\n","# Train the model using the training data\n","log_reg.fit(X_train, y_train)\n","\n","# Predict on the validation set\n","y_val_pred = log_reg.predict(X_val)\n","\n","# Calculate accuracy and other performance metrics on the validation set\n","accuracy_val = accuracy_score(y_val, y_val_pred)\n","classification_rep = classification_report(y_val, y_val_pred)\n","\n","print(accuracy_val, classification_rep)\n"]},{"cell_type":"markdown","metadata":{},"source":["El modelo de regresión logística ha sido entrenado y evaluado con los siguientes resultados en el conjunto de validación arrojando los siguientes resultados:\n","\n","- Precisión (Accuracy): 90.68%\n","\n","- Reporte de clasificación:\n","    Clase 0 (No):\n","    Precisión: 92%\n","    Recall: 98%\n","    F1-Score: 95%\n","    Clase 1 (Sí):\n","    Precisión: 70%\n","    Recall: 34%\n","    F1-Score: 45%"]},{"cell_type":"markdown","metadata":{},"source":["Aplicaremos Grid Search para encontrar mejores hiperparametros:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","# Define the model and parameters for GridSearchCV\n","model = LogisticRegression(random_state=42, max_iter=1000)\n","param_grid = {\n","    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n","    'penalty': ['l1', 'l2', 'none'],  # Types of penalty\n","    'solver': ['liblinear', 'lbfgs', 'saga']  # Solvers that support different penalties\n","}\n","\n","# Setup GridSearchCV to find the best parameters (focusing on maximizing F1-score for the minority class)\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_macro', verbose=1)\n","\n","# Perform the grid search on the training data\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and best score\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","best_params, best_score\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Optimized Model Accuracy: 0.9010843106882054\n","Optimized Model Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.92      0.98      0.95      3987\n","           1       0.65      0.34      0.45       532\n","\n","    accuracy                           0.90      4519\n","   macro avg       0.79      0.66      0.70      4519\n","weighted avg       0.89      0.90      0.89      4519\n","\n"]}],"source":["# Initialize the optimized Logistic Regression model with the best parameters from GridSearch\n","optimized_log_reg = LogisticRegression(\n","    C=best_params['C'],\n","    penalty=best_params['penalty'],\n","    solver=best_params['solver'],\n","    random_state=42,\n","    max_iter=1000\n",")\n","\n","# Train the model using the training data\n","optimized_log_reg.fit(X_train, y_train)\n","\n","# Predict on the validation set\n","y_val_pred_optimized = optimized_log_reg.predict(X_val)\n","\n","# Calculate accuracy and other performance metrics on the validation set\n","accuracy_val_optimized = accuracy_score(y_val, y_val_pred_optimized)\n","classification_rep_optimized = classification_report(y_val, y_val_pred_optimized)\n","\n","# Print the results\n","print(\"Optimized Model Accuracy:\", accuracy_val_optimized)\n","print(\"Optimized Model Classification Report:\\n\", classification_rep_optimized)\n"]},{"cell_type":"markdown","metadata":{},"source":["Gracias al ajuste de hiperparametros se logra mejorar la clasificion de la clase 1 pasando f1 score de 0.42 a 0.45."]},{"cell_type":"markdown","metadata":{},"source":["## Random Forest"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Model Accuracy: 0.9108209780924983\n","Random Forest Model Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.93      0.98      0.95      3987\n","           1       0.71      0.41      0.52       532\n","\n","    accuracy                           0.91      4519\n","   macro avg       0.82      0.69      0.74      4519\n","weighted avg       0.90      0.91      0.90      4519\n","\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Initialize the RandomForestClassifier\n","random_forest = RandomForestClassifier(n_estimators=150, random_state=42)\n","\n","# Train the model using the training data\n","random_forest.fit(X_train, y_train)\n","\n","# Predict on the validation set\n","y_val_pred_rf = random_forest.predict(X_val)\n","\n","# Calculate accuracy and other performance metrics on the validation set\n","accuracy_val_rf = accuracy_score(y_val, y_val_pred_rf)\n","classification_rep_rf = classification_report(y_val, y_val_pred_rf)\n","\n","# Print the results\n","print(\"Random Forest Model Accuracy:\", accuracy_val_rf)\n","print(\"Random Forest Model Classification Report:\\n\", classification_rep_rf)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","\n","# Define the model\n","rf = RandomForestClassifier(random_state=42)\n","\n","# Define the parameter grid\n","param_grid_rf = {\n","    'n_estimators': [50, 100, 200],\n","    'max_features': ['auto', 'sqrt', 'log2'],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Setup GridSearchCV\n","grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n","\n","# Perform the grid search\n","grid_search_rf.fit(X_train, y_train)\n","\n","# Best parameters and best score\n","best_params_rf = grid_search_rf.best_params_\n","best_score_rf = grid_search_rf.best_score_\n","\n","print(\"Best Parameters:\", best_params_rf)\n","print(\"Best Score:\", best_score_rf)\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Model Accuracy: 0.9112635538836026\n","Random Forest Model Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.92      0.98      0.95      3987\n","           1       0.74      0.38      0.50       532\n","\n","    accuracy                           0.91      4519\n","   macro avg       0.83      0.68      0.73      4519\n","weighted avg       0.90      0.91      0.90      4519\n","\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Initialize the RandomForestClassifier with specific parameters\n","random_forest = RandomForestClassifier(\n","    max_depth=20,\n","    max_features='sqrt',\n","    min_samples_leaf=2,\n","    min_samples_split=2,\n","    n_estimators=100,\n","    random_state=42\n",")\n","\n","# Train the model using the training data\n","random_forest.fit(X_train, y_train)\n","\n","# Predict on the validation set\n","y_val_pred_rf = random_forest.predict(X_val)\n","\n","# Calculate accuracy and other performance metrics on the validation set\n","accuracy_val_rf = accuracy_score(y_val, y_val_pred_rf)\n","classification_rep_rf = classification_report(y_val, y_val_pred_rf)\n","\n","# Print the results\n","print(\"Random Forest Model Accuracy:\", accuracy_val_rf)\n","print(\"Random Forest Model Classification Report:\\n\", classification_rep_rf)\n"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest Model Test Accuracy: 0.9061739322859039\n","Random Forest Model Test Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.92      0.98      0.95      3991\n","           1       0.70      0.35      0.46       528\n","\n","    accuracy                           0.91      4519\n","   macro avg       0.81      0.66      0.71      4519\n","weighted avg       0.89      0.91      0.89      4519\n","\n"]}],"source":["# Predict on the test set\n","y_test_pred_rf = random_forest.predict(X_test)\n","\n","# Calculate accuracy and other performance metrics on the test set\n","accuracy_test_rf = accuracy_score(y_test, y_test_pred_rf)\n","classification_rep_test_rf = classification_report(y_test, y_test_pred_rf)\n","\n","# Print the results\n","print(\"Random Forest Model Test Accuracy:\", accuracy_test_rf)\n","print(\"Random Forest Model Test Classification Report:\\n\", classification_rep_test_rf)\n"]},{"cell_type":"markdown","metadata":{"id":"j2PGzN9SpfcP"},"source":["# Conclusiones"]},{"cell_type":"markdown","metadata":{},"source":["\n","Es notable la importancia del ajuste de hiperparametros que han logrado mejora siginificativas en los modelos entrenados.\n","\n","De igual manera la normalizacion y el uso de OneHotEncoder con el fin de alistar los datos han permitido un buen accuracy y prediccion.\n","\n","El modelo tiene un excelente desempeño general, especialmente en la predicción de la clase mayoritaria clase 0. Sin embargo, lucha más con la clase minoritaria clase 1, como lo indican las métricas más bajas de recall y F1-score para esa clase."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
