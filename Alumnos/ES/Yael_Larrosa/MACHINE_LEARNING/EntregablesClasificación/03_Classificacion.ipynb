{"cells":[{"cell_type":"markdown","metadata":{"id":"mYJdsFxinuN5"},"source":["# ENTREGABLE 4"]},{"cell_type":"markdown","metadata":{"id":"IIGQAc67cj6O"},"source":["# INSTRUCCIONES"]},{"cell_type":"markdown","metadata":{"id":"t3VhhDXrcfBJ"},"source":["Utilizar el archivo CSV (`dataset_banco_clean.csv`) con 45189 filas y 17 columnas y aplicar las técnicas de normalización del entregable 3."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"LDnXEh9vn2GX"},"outputs":[],"source":["# imports\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"2C6TxrrjoLca"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>job</th>\n","      <th>marital</th>\n","      <th>education</th>\n","      <th>default</th>\n","      <th>balance</th>\n","      <th>housing</th>\n","      <th>loan</th>\n","      <th>contact</th>\n","      <th>day</th>\n","      <th>month</th>\n","      <th>duration</th>\n","      <th>campaign</th>\n","      <th>pdays</th>\n","      <th>previous</th>\n","      <th>poutcome</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>58</td>\n","      <td>management</td>\n","      <td>married</td>\n","      <td>tertiary</td>\n","      <td>no</td>\n","      <td>2143.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>261.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>44</td>\n","      <td>technician</td>\n","      <td>single</td>\n","      <td>secondary</td>\n","      <td>no</td>\n","      <td>29.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>151.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>33</td>\n","      <td>entrepreneur</td>\n","      <td>married</td>\n","      <td>secondary</td>\n","      <td>no</td>\n","      <td>2.0</td>\n","      <td>yes</td>\n","      <td>yes</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>76.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>47</td>\n","      <td>blue-collar</td>\n","      <td>married</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","      <td>1506.0</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>92.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33</td>\n","      <td>unknown</td>\n","      <td>single</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","      <td>1.0</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>unknown</td>\n","      <td>5</td>\n","      <td>may</td>\n","      <td>198.0</td>\n","      <td>1</td>\n","      <td>-1.0</td>\n","      <td>0</td>\n","      <td>unknown</td>\n","      <td>no</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   age           job  marital  education default  balance housing loan  \\\n","0   58    management  married   tertiary      no   2143.0     yes   no   \n","1   44    technician   single  secondary      no     29.0     yes   no   \n","2   33  entrepreneur  married  secondary      no      2.0     yes  yes   \n","3   47   blue-collar  married    unknown      no   1506.0     yes   no   \n","4   33       unknown   single    unknown      no      1.0      no   no   \n","\n","   contact  day month  duration  campaign  pdays  previous poutcome   y  \n","0  unknown    5   may     261.0         1   -1.0         0  unknown  no  \n","1  unknown    5   may     151.0         1   -1.0         0  unknown  no  \n","2  unknown    5   may      76.0         1   -1.0         0  unknown  no  \n","3  unknown    5   may      92.0         1   -1.0         0  unknown  no  \n","4  unknown    5   may     198.0         1   -1.0         0  unknown  no  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('dataset_banco_clean.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"suOncPeIo2Ln"},"source":["# Objetivo\n","\n","Generar un model de clasificación capaz de predecir la clase de flor en función de las carácterísticas del dataset\n","\n","* Aplicar las técnicas oportunas de procesamiento de datos\n","\n","* Generar split de los datos\n","\n","* Valorar diferentes modelos de clasificación\n","\n","* Comparación entre modelos\n","\n","* Ensemble\n","\n","* Métricas\n","\n","* Conclusiones finales"]},{"cell_type":"markdown","metadata":{},"source":["## Label encoder\n","\n","para que los modelos puedan tratar los datos vamos a pasar todas las columnas a numérico"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["       age  job  marital  education  default  balance  housing  loan  contact  \\\n","0       58    4        1          2        0   2143.0        1     0        2   \n","1       44    9        2          1        0     29.0        1     0        2   \n","2       33    2        1          1        0      2.0        1     1        2   \n","3       47    1        1          3        0   1506.0        1     0        2   \n","4       33   11        2          3        0      1.0        0     0        2   \n","...    ...  ...      ...        ...      ...      ...      ...   ...      ...   \n","45184   51    9        1          2        0    825.0        0     0        0   \n","45185   71    5        0          0        0   1729.0        0     0        0   \n","45186   72    5        1          1        0   5715.0        0     0        0   \n","45187   57    1        1          1        0    668.0        0     0        1   \n","45188   37    2        1          1        0   2971.0        0     0        0   \n","\n","       day  month  duration  campaign  pdays  previous  poutcome  y  \n","0        5      8     261.0         1   -1.0         0         3  0  \n","1        5      8     151.0         1   -1.0         0         3  0  \n","2        5      8      76.0         1   -1.0         0         3  0  \n","3        5      8      92.0         1   -1.0         0         3  0  \n","4        5      8     198.0         1   -1.0         0         3  0  \n","...    ...    ...       ...       ...    ...       ...       ... ..  \n","45184   17      9     977.0         3   -1.0         0         3  1  \n","45185   17      9     456.0         2   -1.0         0         3  1  \n","45186   17      9    1127.0         5  184.0         3         2  1  \n","45187   17      9     508.0         4   -1.0         0         3  0  \n","45188   17      9     361.0         2  188.0        11         1  0  \n","\n","[45189 rows x 17 columns]\n"]}],"source":["from sklearn.preprocessing import LabelEncoder\n","\n","columnas_encoding= ['job','marital','education','default','housing','loan','contact','month','poutcome','y']\n","\n","le = LabelEncoder()\n","\n","for columna in columnas_encoding:\n","    df[columna]= le.fit_transform(df[columna])\n","\n","print(df)"]},{"cell_type":"markdown","metadata":{},"source":["## Separar la X de la y"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"oGEq8EGTpp7g"},"outputs":[{"name":"stdout","output_type":"stream","text":["       age  job  marital  education  default  balance  housing  loan  contact  \\\n","0       58    4        1          2        0   2143.0        1     0        2   \n","1       44    9        2          1        0     29.0        1     0        2   \n","2       33    2        1          1        0      2.0        1     1        2   \n","3       47    1        1          3        0   1506.0        1     0        2   \n","4       33   11        2          3        0      1.0        0     0        2   \n","...    ...  ...      ...        ...      ...      ...      ...   ...      ...   \n","45184   51    9        1          2        0    825.0        0     0        0   \n","45185   71    5        0          0        0   1729.0        0     0        0   \n","45186   72    5        1          1        0   5715.0        0     0        0   \n","45187   57    1        1          1        0    668.0        0     0        1   \n","45188   37    2        1          1        0   2971.0        0     0        0   \n","\n","       day  month  duration  campaign  pdays  previous  poutcome  \n","0        5      8     261.0         1   -1.0         0         3  \n","1        5      8     151.0         1   -1.0         0         3  \n","2        5      8      76.0         1   -1.0         0         3  \n","3        5      8      92.0         1   -1.0         0         3  \n","4        5      8     198.0         1   -1.0         0         3  \n","...    ...    ...       ...       ...    ...       ...       ...  \n","45184   17      9     977.0         3   -1.0         0         3  \n","45185   17      9     456.0         2   -1.0         0         3  \n","45186   17      9    1127.0         5  184.0         3         2  \n","45187   17      9     508.0         4   -1.0         0         3  \n","45188   17      9     361.0         2  188.0        11         1  \n","\n","[45189 rows x 16 columns]\n","0        0\n","1        0\n","2        0\n","3        0\n","4        0\n","        ..\n","45184    1\n","45185    1\n","45186    1\n","45187    0\n","45188    0\n","Name: y, Length: 45189, dtype: int32\n"]}],"source":["X = df.drop(columns='y')\n","y=df['y']\n","\n","print(X)\n","print(y)"]},{"cell_type":"markdown","metadata":{},"source":["## Realizar los splits"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(31632, 16) (31632,)\n","(6778, 16) (6778,)\n","(6779, 16) (6779,)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=30/100, random_state=42)\n","X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size=15/30, random_state=42)\n","print(X_train.shape, y_train.shape)\n","print(X_val.shape, y_val.shape)\n","print(X_test.shape, y_test.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Normalización"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n","[0.         0.         0.         0.         0.         0.00739799\n"," 0.         0.         0.         0.         0.         0.00025773\n"," 0.         0.         0.         0.        ] [0.85714286 1.         1.         1.         1.         0.1395572\n"," 1.         1.         1.         1.         1.         1.26726804\n"," 0.94736842 0.96215596 1.1372549  1.        ]\n","[0.         0.         0.         0.         0.         0.01101109\n"," 0.         0.         0.         0.         0.         0.00025773\n"," 0.         0.         0.         0.        ] [0.93506494 1.         1.         1.         1.         0.20566855\n"," 1.         1.         1.         1.         1.         0.97525773\n"," 1.0877193  0.95412844 0.78431373 1.        ]\n"]}],"source":["from sklearn.preprocessing import MinMaxScaler\n","\n","def normalizar(xtr, xvl, xts):\n","    scaler = MinMaxScaler()\n","    xtr_s = scaler.fit_transform(xtr)\n","    xvl_s = scaler.transform(xvl)\n","    xts_s = scaler.transform(xts)\n","    return xtr_s, xvl_s, xts_s\n","\n","x_train_s, x_val_s, x_test_s = normalizar(X_train,X_val,X_test)\n","\n","# Verificar\n","print(x_train_s.min(axis=0),x_train_s.max(axis=0))\n","print(x_val_s.min(axis=0),x_val_s.max(axis=0))\n","print(x_test_s.min(axis=0),x_test_s.max(axis=0))"]},{"cell_type":"markdown","metadata":{},"source":["## Aplicar modelos\n","\n","A continuación, procedo a probar direfentes modelos con el set de train y val para tener una primera visión de que modelos pueden trabajar mejor con el problema presentado. También podría hacer un random search o un grid search, que lo haré con los me mejor resultado de de los modelos seleccionados."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Forest: Precisión en el conjunto de prueba: 0.9058719386249631\n","Logistic Regression: Precisión en el conjunto de prueba: 0.8925936854529359\n","Support Vector Machine: Precisión en el conjunto de prueba: 0.8909707878430215\n","K-Nearest Neighbors: Precisión en el conjunto de prueba: 0.8912658601357333\n","Naive Bayes: Precisión en el conjunto de prueba: 0.8406609619356742\n","XGBoost: Precisión en el conjunto de prueba: 0.9085275892593685\n","Decision Tree: Precisión en el conjunto de prueba: 0.8741516671584538\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from xgboost import XGBClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score\n","\n","\n","models = {\n","    \"Random Forest\": RandomForestClassifier(),\n","    \"Logistic Regression\": LogisticRegression(),\n","    \"Support Vector Machine\": SVC(),\n","    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n","    \"Naive Bayes\": GaussianNB(),\n","    \"XGBoost\": XGBClassifier(),\n","    \"Decision Tree\": DecisionTreeClassifier() \n","}\n","\n","\n","for name, model in models.items():\n","    model.fit(x_train_s, y_train)\n","    y_pred = model.predict(x_val_s)\n","    accuracy = accuracy_score(y_val, y_pred)\n","    print(f\"{name}: Precisión en el conjunto de prueba: {accuracy}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["De este primero análisis podemos detectar que los modelos de naive-Bayes y el arbol de decisión no son los modelos que mejor soluciona el problema. \n","\n","Vamos a hacer un grid search para los otros modelos a ver si conseguimos mejoras."]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Modelo: XGBoost\n","Mejores hiperparámetros encontrados: {'learning_rate': 0.1, 'n_estimators': 100}\n","Precisión en el conjunto de prueba: 0.9082325169666569\n","\n","Modelo: K-Nearest Neighbors\n","Mejores hiperparámetros encontrados: {'n_neighbors': 7}\n","Precisión en el conjunto de prueba: 0.8909707878430215\n","\n","Modelo: Support Vector Machine\n","Mejores hiperparámetros encontrados: {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n","Precisión en el conjunto de prueba: 0.8924461493065801\n","\n","Modelo: Logistic Regression\n","Mejores hiperparámetros encontrados: {'C': 10, 'solver': 'lbfgs'}\n","Precisión en el conjunto de prueba: 0.8924461493065801\n","\n","Modelo: Random Forest\n","Mejores hiperparámetros encontrados: {'max_depth': 20, 'n_estimators': 200}\n","Precisión en el conjunto de prueba: 0.9079374446739451\n","\n"]}],"source":["from sklearn.model_selection import GridSearchCV\n","\n","models = {\n","    \"XGBoost\": (XGBClassifier(), {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2]}),\n","    \"K-Nearest Neighbors\": (KNeighborsClassifier(), {'n_neighbors': [3, 5, 7]}),\n","    \"Support Vector Machine\": (SVC(), {'C': [0.1, 1, 10], 'gamma': [0.1, 0.01, 0.001], 'kernel': ['rbf']}),\n","    \"Logistic Regression\": (LogisticRegression(), {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}),\n","    \"Random Forest\": (RandomForestClassifier(), {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]})\n","}\n","\n","for name, (model, params) in models.items():\n","    grid_search = GridSearchCV(estimator=model, param_grid=params, cv=5, scoring='accuracy')\n","    grid_search.fit(x_train_s, y_train)\n","    \n","    # Obtener el mejor modelo\n","    best_model = grid_search.best_estimator_\n","    \n","    # Predecir en el conjunto de prueba\n","    y_pred = best_model.predict(x_val_s)\n","    \n","    # Calcular la precisión del modelo en el conjunto de prueba\n","    accuracy = accuracy_score(y_val, y_pred)\n","    \n","    # Imprimir resultados\n","    print(f\"Modelo: {name}\")\n","    print(f\"Mejores hiperparámetros encontrados: {grid_search.best_params_}\")\n","    print(f\"Precisión en el conjunto de prueba: {accuracy}\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["Vemos que mediante el grid search tampoco mejoran mucho los resultados del primer barrido realizado por lo que procedo a realizar ensembles para ver si mejora la capacidad de predicción ya que la principal ventaja de los ensembles es que permiten reducir el sobreajuste. \n","\n","Los modelos que selecciono para el ensemble son el random forest y el XGBoost ya que son los modelos que mejor resultado han dado. "]},{"cell_type":"markdown","metadata":{},"source":["## Ensembles"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El F1-score del modelo Random Forest es: 0.5047923322683706\n","El accuracy del modelo Random Forest es: 0.9085275892593685\n","El F1-score del modelo XGBoost es: 0.5244648318042814\n","El accuracy del modelo XGBoost es: 0.9082325169666569\n","El F1-score del ensemble es: 0.5293657008613939\n","El accuracy del ensemble es: 0.9113307760401298\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","\n","rf_clf = RandomForestClassifier(n_estimators=200, max_depth=20)\n","xgb_clf = XGBClassifier(learning_rate=0.1, n_estimators=100)\n","\n","rf_clf.fit(x_train_s, y_train)\n","xgb_clf.fit(x_train_s, y_train)\n","\n","rf_pred = rf_clf.predict(x_val_s)\n","xgb_pred = xgb_clf.predict(x_val_s)\n","\n","rf_f1 = f1_score(y_val, rf_pred)\n","xgb_f1 = f1_score(y_val, xgb_pred)\n","\n","rf_accuracy = accuracy_score(y_val, rf_pred)\n","xgb_accuracy = accuracy_score(y_val, xgb_pred)\n","\n","voting_clf = VotingClassifier(estimators=[('random_forest', rf_clf), ('xgboost', xgb_clf)], voting='soft')\n","\n","voting_clf.fit(x_train_s, y_train)\n","\n","ensemble_pred = voting_clf.predict(x_val_s)\n","\n","ensemble_f1 = f1_score(y_val, ensemble_pred)\n","\n","ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n","\n","print(f'El F1-score del modelo Random Forest es: {rf_f1}')\n","print(f'El accuracy del modelo Random Forest es: {rf_accuracy}')\n","print(f'El F1-score del modelo XGBoost es: {xgb_f1}')\n","print(f'El accuracy del modelo XGBoost es: {xgb_accuracy}')\n","print(f'El F1-score del ensemble es: {ensemble_f1}')\n","print(f'El accuracy del ensemble es: {ensemble_accuracy}')\n"]},{"cell_type":"markdown","metadata":{},"source":["Podemos ver que el accuracy (precisión del modelo) del en ensemble es algo mejor que unicamente utilizando el modelo XGBoost o el Random Forest y además vemos que el f1-score (permite equilibrar la precisión teniendo en cuenta falsos positivos y falsos negativos) del ensemble es mejor que el de los modelos por separado pero aun así no es extremadamente alto. Un F1-score de 0.52 indica que la precisión y el recall están relativamente equilibrados, pero aún hay errores tanto en los falsos positivos como en los falsos negativos."]},{"cell_type":"markdown","metadata":{},"source":["A continuación voy a realizar un ensemble de los modelos de regrasión logistica y de XGB classifier ya que daba bien resultado previamente."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El F1-score del modelo Logistic Regression es: 0.3037249283667622\n","El accuracy del modelo Logistic Regression es: 0.8924461493065801\n","El F1-score del modelo XGBoost es: 0.5244648318042814\n","El accuracy del modelo XGBoost es: 0.9082325169666569\n","El F1-score del ensemble es: 0.4396551724137931\n","El accuracy del ensemble es: 0.9041015048686928\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","# Instanciar los modelos con los hiperparámetros dados\n","logistic_regression = LogisticRegression(C=10, solver='lbfgs')\n","xgboost = XGBClassifier(learning_rate=0.1, n_estimators=100)\n","\n","# Entrenar los modelos\n","logistic_regression.fit(x_train_s, y_train)\n","xgboost.fit(x_train_s, y_train)\n","\n","# Predecir con los modelos\n","lr_pred = logistic_regression.predict(x_val_s)\n","xgb_pred = xgboost.predict(x_val_s)\n","\n","# Calcular el F1-score para cada modelo\n","lr_f1 = f1_score(y_val, lr_pred)\n","xgb_f1 = f1_score(y_val, xgb_pred)\n","\n","# Calcular el accuracy para cada modelo\n","lr_accuracy = accuracy_score(y_val, lr_pred)\n","xgb_accuracy = accuracy_score(y_val, xgb_pred)\n","\n","# Crear el ensemble de clasificación\n","ensemble = VotingClassifier([('logistic_regression', logistic_regression), ('xgboost', xgboost)], voting='soft')\n","\n","# Entrenar el ensemble\n","ensemble.fit(x_train_s, y_train)\n","\n","# Predecir con el ensemble\n","ensemble_pred = ensemble.predict(x_val_s)\n","\n","# Calcular el F1-score para el ensemble\n","ensemble_f1 = f1_score(y_val, ensemble_pred)\n","\n","# Calcular el accuracy para el ensemble\n","ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n","\n","print(f'El F1-score del modelo Logistic Regression es: {lr_f1}')\n","print(f'El accuracy del modelo Logistic Regression es: {lr_accuracy}')\n","print(f'El F1-score del modelo XGBoost es: {xgb_f1}')\n","print(f'El accuracy del modelo XGBoost es: {xgb_accuracy}')\n","print(f'El F1-score del ensemble es: {ensemble_f1}')\n","print(f'El accuracy del ensemble es: {ensemble_accuracy}')\n"]},{"cell_type":"markdown","metadata":{},"source":["Vemos que el ensemble o ha mejorado en gran medida los modelos por separado por lo que opto por probar otro ensemble de SVC y XGBClassifier."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El F1-score del modelo SVM es: 0.21528525296017223\n","El accuracy del modelo SVM es: 0.8924461493065801\n","El F1-score del modelo XGBoost es: 0.5244648318042814\n","El accuracy del modelo XGBoost es: 0.9082325169666569\n","El F1-score del ensemble es: 0.20331491712707184\n","El accuracy del ensemble es: 0.893626438477427\n"]}],"source":["from sklearn.svm import SVC\n","from xgboost import XGBClassifier\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","svm = SVC(C=10, gamma=0.1, kernel='rbf')\n","xgboost = XGBClassifier(learning_rate=0.1, n_estimators=100)\n","\n","svm.fit(x_train_s, y_train)\n","xgboost.fit(x_train_s, y_train)\n","\n","svm_pred = svm.predict(x_val_s)\n","xgb_pred = xgboost.predict(x_val_s)\n","\n","svm_f1 = f1_score(y_val, svm_pred)\n","xgb_f1 = f1_score(y_val, xgb_pred)\n","svm_accuracy = accuracy_score(y_val, svm_pred)\n","xgb_accuracy = accuracy_score(y_val, xgb_pred)\n","\n","\n","ensemble = VotingClassifier([('svm', svm), ('xgboost', xgboost)], voting='hard')\n","\n","ensemble.fit(x_train_s, y_train)\n","\n","ensemble_pred = ensemble.predict(x_val_s)\n","\n","ensemble_f1 = f1_score(y_val, ensemble_pred)\n","ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n","\n","print(f'El F1-score del modelo SVM es: {svm_f1}')\n","print(f'El accuracy del modelo SVM es: {svm_accuracy}')\n","print(f'El F1-score del modelo XGBoost es: {xgb_f1}')\n","print(f'El accuracy del modelo XGBoost es: {xgb_accuracy}')\n","print(f'El F1-score del ensemble es: {ensemble_f1}')\n","print(f'El accuracy del ensemble es: {ensemble_accuracy}')\n"]},{"cell_type":"markdown","metadata":{},"source":["De todos los modelos y pruebas realizadas vemos que el mejor resultado encontrado el la aplicación del ensemble de los modelos XGBoost y random forest tanto en accuracy como en f1-score. Este modelo utiliza la técnica de aumento de gradiente, en el que múltiples modelos como árboles de decisión se combinan para construir un modelo más fuerte.\n","\n","Vamos a ver ese modelo que resultados nos da para el set de test, que es la prueba definitiva en la que eliminamos tanto sesgos de los modelos como sesgos causados por la elección del modelo. "]},{"cell_type":"markdown","metadata":{},"source":["## modelo seleccionado"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El F1-score del ensemble es: 0.528125\n","El accuracy del ensemble es: 0.9108881676010623\n"]}],"source":["from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, f1_score\n","\n","rf_clf = RandomForestClassifier(n_estimators=200, max_depth=20)\n","xgb_clf = XGBClassifier(learning_rate=0.1, n_estimators=100)\n","\n","voting_clf = VotingClassifier(estimators=[('random_forest', rf_clf), ('xgboost', xgb_clf)], voting='soft')\n","\n","voting_clf.fit(x_train_s, y_train)\n","\n","ensemble_pred = voting_clf.predict(x_val_s)\n","\n","ensemble_f1 = f1_score(y_val, ensemble_pred)\n","ensemble_accuracy = accuracy_score(y_val, ensemble_pred)\n","print(f'El F1-score del ensemble es: {ensemble_f1}')\n","print(f'El accuracy del ensemble es: {ensemble_accuracy}')\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["El F1-score del ensemble en el set de test es: 0.5273408239700375\n","El accuracy del ensemble en el set de test es: 0.9069184245463933\n"]}],"source":["ensemble_test = voting_clf.predict(x_test_s)\n","\n","xgb_f1 = f1_score(y_test, ensemble_test)\n","xgb_accuracy = accuracy_score(y_test, ensemble_test)\n","\n","print(f'El F1-score del ensemble en el set de test es: {xgb_f1}')\n","print(f'El accuracy del ensemble en el set de test es: {xgb_accuracy}')"]},{"cell_type":"markdown","metadata":{"id":"j2PGzN9SpfcP"},"source":["# Conclusiones"]},{"cell_type":"markdown","metadata":{},"source":["A modo de conclusión decir que tenemos un modelo que tiene un accuracy alto lo que indica que el 90% de los datos que predice son correctos pero tiene un f1-score de 0,52 lo que indica que predice tanto falsos positivos como falsos negativos de manera equilibrada pero que seria interesante mejorar el parámetro aumentando el valor ya que en ese modo determinaría que el modelo es capaz de clasificar correctamente tanto instacias positivas como negativas. También destacar que se ha podido comprobar que el ensemble de modelos pueden llegar a hacer una predicción más robusta."]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
