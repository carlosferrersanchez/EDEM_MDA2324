{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MXAi-QLhFW6"
      },
      "source": [
        "<font color=\"#CA3532\"><h1 align=\"left\">Master Data Analytics. EDEM.</h1></font>\n",
        "<font color=\"#6E6E6E\"><h2 align=\"left\">Herramientas MLOps.</h2></font>\n",
        "<font color=\"#6E6E6E\"><h2 align=\"left\">Tarea 1. Pipeline entrenamiento de modelos.</h2></font>\n",
        "#### Daniel Ruiz Riquelme\n",
        "https://docs.metaflow.org/metaflow/basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZpu-TTehFXA"
      },
      "source": [
        "##  Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wgALBuThFXB",
        "outputId": "81d79a57-906f-41c3-9688-bbcf3929a0a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting metaflow\n",
            "  Downloading metaflow-2.12.5-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from metaflow) (2.31.0)\n",
            "Collecting boto3 (from metaflow)\n",
            "  Downloading boto3-1.34.131-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m825.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.35.0,>=1.34.131 (from boto3->metaflow)\n",
            "  Downloading botocore-1.34.131-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->metaflow)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->metaflow)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->metaflow) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.131->boto3->metaflow) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.131->boto3->metaflow) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, metaflow\n",
            "Successfully installed boto3-1.34.131 botocore-1.34.131 jmespath-1.0.1 metaflow-2.12.5 s3transfer-0.10.1\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install metaflow\n",
        "!pip install scikit-learn\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF6ljIDnhFXD"
      },
      "source": [
        "## Set username"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IclSfnOphFXE"
      },
      "outputs": [],
      "source": [
        "# Set username for workflows\n",
        "import os\n",
        "os.environ[\"USERNAME\"] = \"rafa\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owvmr7EZhFXE",
        "outputId": "0869ab0e-bd55-41c1-ab64-1958ee54c69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing metaflow_trainingflow.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile metaflow_trainingflow.py\n",
        "from metaflow import FlowSpec, Parameter, step\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pickle\n",
        "\n",
        "class TrainingFlow(FlowSpec):\n",
        "    # Define the parameters for the flow\n",
        "    max_depth = Parameter('max_depth', default=2, help='Max depth of the random forest classifier')\n",
        "    n_estimators = Parameter('n_estimators', default=100, help='Number of estimators for the random forest classifier')\n",
        "    random_state = Parameter('random_state', default=0, help='Random state for the random forest classifier')\n",
        "\n",
        "    @step\n",
        "    def start(self):\n",
        "        # Start the flow\n",
        "        self.next(self.ingest_data)\n",
        "\n",
        "    @step\n",
        "    def ingest_data(self):\n",
        "        from sklearn.datasets import load_iris\n",
        "\n",
        "        # Load the iris dataset\n",
        "        iris = load_iris()\n",
        "\n",
        "        #pylint: disable=no-member\n",
        "        self.X = iris.data\n",
        "        self.y = iris.target\n",
        "        #pylint: enable=no-member\n",
        "\n",
        "        self.next(self.split_data)\n",
        "\n",
        "    @step\n",
        "    def split_data(self):\n",
        "        #Split the data into train and test\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            self.X, self.y, test_size=0.2, random_state=self.random_state\n",
        "        )\n",
        "\n",
        "        self.next(self.train)\n",
        "\n",
        "    @step\n",
        "    def train(self):\n",
        "        # Train the model\n",
        "        self.model = RandomForestClassifier(\n",
        "            max_depth=self.max_depth,\n",
        "            n_estimators=self.n_estimators,\n",
        "            random_state=self.random_state\n",
        "        )\n",
        "\n",
        "        self.model.fit(self.X_train, self.y_train)\n",
        "\n",
        "        self.next(self.show_metrics)\n",
        "\n",
        "    @step\n",
        "    def show_metrics(self):\n",
        "        # Print some metrics\n",
        "        self.y_pred = self.model.predict(self.X_test)\n",
        "\n",
        "        self.accuracy = accuracy_score(self.y_test, self.y_pred)\n",
        "\n",
        "        print(f'Accuracy: {self.accuracy}')\n",
        "        print('Classification Report:')\n",
        "        print(classification_report(self.y_test, self.y_pred))\n",
        "\n",
        "        self.next(self.register_model)\n",
        "\n",
        "    @step\n",
        "    def register_model(self):\n",
        "        # Save the model in a pickle file in local storage\n",
        "        with open('random_forest_model.pkl', 'wb') as f:\n",
        "            pickle.dump(self.model, f)\n",
        "\n",
        "        print(\"Model saved as random_forest_model.pkl\")\n",
        "\n",
        "        self.next(self.end)\n",
        "\n",
        "    @step\n",
        "    def end(self):\n",
        "        pass\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    TrainingFlow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG4AlydmhFXE",
        "outputId": "edf7f6eb-2d96-4d14-fd06-abd0c58780f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[35m\u001b[1mMetaflow 2.12.5\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTrainingFlow\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:rafa\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[22mCreating local datastore in current directory (/content/.metaflow)\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
            "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
            "\u001b[32m\u001b[22m    Pylint not found, so extra checks are disabled.\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:39.727 \u001b[0m\u001b[1mWorkflow starting (run-id 1719052839726376):\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:39.737 \u001b[0m\u001b[32m[1719052839726376/start/1 (pid 2292)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:40.874 \u001b[0m\u001b[32m[1719052839726376/start/1 (pid 2292)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:40.879 \u001b[0m\u001b[32m[1719052839726376/ingest_data/2 (pid 2306)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:42.461 \u001b[0m\u001b[32m[1719052839726376/ingest_data/2 (pid 2306)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:42.467 \u001b[0m\u001b[32m[1719052839726376/split_data/3 (pid 2316)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:44.229 \u001b[0m\u001b[32m[1719052839726376/split_data/3 (pid 2316)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:44.235 \u001b[0m\u001b[32m[1719052839726376/train/4 (pid 2330)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:45.857 \u001b[0m\u001b[32m[1719052839726376/train/4 (pid 2330)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:45.862 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:46.866 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22mAccuracy: 1.0\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:46.871 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22mClassification Report:\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:46.872 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22mprecision    recall  f1-score   support\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.153 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22m0       1.00      1.00      1.00        11\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22m1       1.00      1.00      1.00        13\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22m2       1.00      1.00      1.00         6\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22maccuracy                           1.00        30\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22mmacro avg       1.00      1.00      1.00        30\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22mweighted avg       1.00      1.00      1.00        30\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.154 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[22m\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.155 \u001b[0m\u001b[32m[1719052839726376/show_metrics/5 (pid 2340)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:47.159 \u001b[0m\u001b[32m[1719052839726376/register_model/6 (pid 2354)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:48.109 \u001b[0m\u001b[32m[1719052839726376/register_model/6 (pid 2354)] \u001b[0m\u001b[22mModel saved as random_forest_model.pkl\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:48.299 \u001b[0m\u001b[32m[1719052839726376/register_model/6 (pid 2354)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:48.303 \u001b[0m\u001b[32m[1719052839726376/end/7 (pid 2364)] \u001b[0m\u001b[1mTask is starting.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:49.598 \u001b[0m\u001b[32m[1719052839726376/end/7 (pid 2364)] \u001b[0m\u001b[1mTask finished successfully.\u001b[0m\n",
            "\u001b[35m2024-06-22 10:40:49.598 \u001b[0m\u001b[1mDone!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python metaflow_trainingflow.py run --max_depth 2 --n_estimators 100 --random_state 0"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "productionalization",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "5ed29f95de7cc8ac0f18a32ccae5fbddd3dba9010e060d505f2ebe31fc64f080"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}